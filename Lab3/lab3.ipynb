{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16b4208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import *\n",
    "from nltk import word_tokenize\n",
    "import itertools\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792d4a4",
   "metadata": {},
   "source": [
    "## Выгрузка данных из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae07ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.windows.x', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "remove = ['headers', 'footers', 'quotes']\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories, remove=remove)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, categories=categories, remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924c81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = pd.DataFrame(twenty_train, columns=['data', 'target']).replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True)\n",
    "twenty_test = pd.DataFrame(twenty_test, columns=['data', 'target']).replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3233496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    nltk_tokens = word_tokenize(data)\n",
    "    line = ''\n",
    "    for word in nltk_tokens:\n",
    "        line += ' ' + porter_stemmer.stem(word)\n",
    "    return line\n",
    "\n",
    "twenty_train.insert(loc=1, column='data_stemmed', value=twenty_train['data'].apply(lambda text: stemming(text)))\n",
    "twenty_test.insert(loc=1, column='data_stemmed', value=twenty_test['data'].apply(lambda text: stemming(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78c74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings \n",
    "from sklearn.exceptions import FitFailedWarning, ConvergenceWarning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32fe78d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to 0.0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 2.02 s, total: 12.2 s\n",
      "Wall time: 6min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    'RAndomForestClassifier': {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__n_neighbors': (1, 3, 5, 10),\n",
    "        'clf__p': (1, 2)\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__criterion': ('gini', 'entropy'),\n",
    "        'clf__max_depth': [*range(1,5,1), *range(5,101,20)]\n",
    "    },\n",
    "    'svm': [{\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__loss': ['squared_hinge'],\n",
    "        'clf__penalty': ('l1', 'l2')\n",
    "    },\n",
    "        {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__loss': ['hinge'],\n",
    "        'clf__penalty': ['l2']\n",
    "    }],\n",
    "}\n",
    "\n",
    "gs = {}\n",
    "for clf, param in parameters.items():\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', eval(clf)())\n",
    "    ])\n",
    "    gs[clf] = GridSearchCV(text_clf, param, n_jobs=-1, error_score=0.0)\n",
    "    gs[clf].fit(X = twenty_train['data'], y = twenty_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca430db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    comp.windows.x       0.75      0.56      0.64       395\n",
      "rec.sport.baseball       0.43      0.57      0.49       397\n",
      "  rec.sport.hockey       0.51      0.48      0.49       399\n",
      "\n",
      "          accuracy                           0.53      1191\n",
      "         macro avg       0.56      0.53      0.54      1191\n",
      "      weighted avg       0.56      0.53      0.54      1191\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    comp.windows.x       0.87      0.80      0.83       395\n",
      "rec.sport.baseball       0.63      0.81      0.71       397\n",
      "  rec.sport.hockey       0.82      0.64      0.72       399\n",
      "\n",
      "          accuracy                           0.75      1191\n",
      "         macro avg       0.77      0.75      0.75      1191\n",
      "      weighted avg       0.77      0.75      0.75      1191\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    comp.windows.x       0.98      0.93      0.96       395\n",
      "rec.sport.baseball       0.85      0.90      0.87       397\n",
      "  rec.sport.hockey       0.90      0.88      0.89       399\n",
      "\n",
      "          accuracy                           0.91      1191\n",
      "         macro avg       0.91      0.91      0.91      1191\n",
      "      weighted avg       0.91      0.91      0.91      1191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf, param in parameters.items():\n",
    "    predicted = gs[clf].predict(twenty_test['data'])\n",
    "    print(metrics.classification_report(twenty_test.target, predicted, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c2b3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = {}\n",
    "def highlight_max(x, color):\n",
    "\n",
    "    return np.where(x == np.nanmax(x.to_numpy()), f\"color: {color};\", None)\n",
    "\n",
    "total_style = pd.Series(\"font-weight: bold;\", index=[1])\n",
    "\n",
    "for clf, param in parameters.items():\n",
    "    predicted = gs[clf].predict(twenty_test['data'])\n",
    "    \n",
    "    pd.DataFrame(gs[clf].cv_results_).to_excel('all' + clf + '.xlsx')\n",
    "    pd.DataFrame(classification_report(predicted, twenty_test.target, output_dict=True)).to_excel('best' + clf + '.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339715b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
